---
title: "Caso 2"
author: "Sebastián Lozano, Jherson Guzman"
date: "7/10/2023"
output: pdf_document
---

```{r setup, include=FALSE}
setwd("C:/Bayesiana/Caso2")
```


```{r, include=FALSE,include=FALSE}
Sys.setlocale(category = "LC_COLLATE", locale = "Spanish_Colombia.utf8")
Sys.setlocale(category = "LC_CTYPE", locale = "Spanish_Colombia.utf8")
Sys.setlocale(category = "LC_MONETARY", locale = "Spanish_Colombia.utf8")
Sys.setlocale(category = "LC_NUMERIC", locale = "C")
Sys.setlocale(category = "LC_TIME", locale = "Spanish_Colombia.utf8")
```


```{r cargar datos, y librería,include=FALSE}
library(readr)
library(readxl)
library(dplyr)
library(ggplot2)

#setwd("C:/Users/57300/OneDrive/Documentos/GitHub/BayesianStatsCase2")
Saber11 <- read_delim("C:/Bayesiana/Caso2/SB11_20222.TXT", 
  delim = ";", escape_double = FALSE, locale = locale(), 
  trim_ws = TRUE)

```

```{r Tratamiento de datos, include=FALSE}
#Nacionalidad colombiana
#Residencia en Colombia
#Proceso de investigación en el Icfes en estado de “Publicar”.
#Ubicación del colegio no es San Andrés.
#Sin datos faltantes en la ubicación del colegio por municipio, la ubicación del colegio por departamento y el puntaje global

datos <- Saber11 %>%
  filter(ESTU_NACIONALIDAD == "COLOMBIA"&
           ESTU_PAIS_RESIDE == "COLOMBIA" &
            COLE_COD_DEPTO_UBICACION != 88 &
           ESTU_ESTADOINVESTIGACION=="PUBLICAR" 
           ) %>%
  arrange(COLE_COD_DEPTO_UBICACION,COLE_COD_MCPIO_UBICACION)%>%
  as.data.frame()

nrow(datos)

#ya hay 525061

# cambiamos COLE_COD_DEPTO_UBICACION a char
datos$COLE_COD_DEPTO_UBICACION<-as.character(datos$COLE_COD_DEPTO_UBICACION)
datos$COLE_COD_DEPTO_UBICACION<-ifelse(datos$COLE_COD_DEPTO_UBICACION=="5","05",datos$COLE_COD_DEPTO_UBICACION)
datos$COLE_COD_DEPTO_UBICACION<-ifelse(datos$COLE_COD_DEPTO_UBICACION=="8","08",datos$COLE_COD_DEPTO_UBICACION)

# cambiamos COLE_COD_MCPIO_UBICACION a char
datos$COLE_COD_MCPIO_UBICACION<-as.character(datos$COLE_COD_MCPIO_UBICACION)
datos$COLE_COD_MCPIO_UBICACION<-ifelse(datos$COLE_COD_DEPTO_UBICACION=="05",paste("0",datos$COLE_COD_MCPIO_UBICACION,sep=""),datos$COLE_COD_MCPIO_UBICACION)
datos$COLE_COD_MCPIO_UBICACION<-ifelse(datos$COLE_COD_DEPTO_UBICACION=="08",paste("0",datos$COLE_COD_MCPIO_UBICACION,sep=""),datos$COLE_COD_MCPIO_UBICACION)


# Revisamos que no hayan datos faltantes
sum(is.na(datos$COLE_COD_MCPIO_UBICACION))
sum(is.na(datos$COLE_COD_DEPTO_UBICACION))
sum(is.na(datos$PUNT_GLOBAL))

##Guardamos los datos, para su posterior manipulación.
#save(datos, file = "saber11modificado.rdata")

```

## Punto 1
```{r preparacion de la base de datos, include=FALSE}
combinados <- cbind(datos$COLE_DEPTO_UBICACION,datos$COLE_COD_DEPTO_UBICACION)
cod <- as.data.frame(unique(combinados))
cod <- setNames(cod, c("dep", "cod_dep"))
```

```{r, include=FALSE}
pobreza_monetaria <- read_excel("C:/Bayesiana/Caso2/pobreza monetaria.xls",sheet = "Pobreza Monetaria (%)", range = "A16:P40")

pobreza_monetaria <- pobreza_monetaria[,c(1,16)]
pobreza_monetaria <- setNames(pobreza_monetaria,c("dep","IP2018"))

codigos_departamentos <- c("05", "08", "11", "13", "15", "17", "18", "19", "20", "27", "23", "25", "41", "44", "47", "50", "52", "54", "63", "66", "68", "70", "73", "76")

pobreza_monetaria$cod_dep <- codigos_departamentos

punt_muestrales <- datos %>%
  group_by(COLE_COD_DEPTO_UBICACION) %>%
  summarise(puntmedio = mean(PUNT_GLOBAL)) %>%
  as.data.frame()

Mapa <- punt_muestrales %>%
  full_join(pobreza_monetaria,by = c("COLE_COD_DEPTO_UBICACION"="cod_dep"))%>%
  select(COLE_COD_DEPTO_UBICACION,dep,IP2018,puntmedio) %>%
  as.data.frame()

Mapa <- setNames(Mapa,c("cod_dep","dep","IP2018","puntmedio"))
```

```{r gráficas, include=FALSE}
library(sf)
setwd("C:/Bayesiana/Caso2/misc")

deptoshp <- st_read("C:/Bayesiana/Caso2/misc/MGN_DPTO_POLITICO.shp",quiet=TRUE) 

mapdeptos <- deptoshp %>%
  left_join(Mapa,by=c("DPTO_CCDGO"="cod_dep")) 

mundoshp <- st_read("C:/Bayesiana/Caso2/misc/admin00.shp",quiet=TRUE)
mundocol <- mundoshp %>% 
            filter(CNTRY_NAME %in% c("Peru","Brazil","Venezuela","Ecuador","Panama"))
str(mundocol)
```

```{r}
library(ggplot2)
box <- st_bbox(mapdeptos)

plot1 <- ggplot() +
  geom_sf(data = mundocol) +
  geom_sf(data = mapdeptos, aes(fill = puntmedio), col = "darkgray", linetype = "solid") +
  coord_sf(xlim = c(box$xmin, box$xmax), ylim = c(box$ymin, box$ymax), expand = FALSE) +
  geom_sf_text(data = mapdeptos, aes(label = ifelse(puntmedio < quantile(puntmedio, probs = 0.10, na.rm = TRUE), DPTO_CNMBR, "")), col = "black",
               fontface = "bold", size = 2, fun.geometry = function(x) sf::st_centroid(x)) +
  labs(x = "Longitud", y = "Latitud", title = "Puntaje medio en las \npruebas Saber Pro \ndepartamento en 2022-II", fill = "Puntaje \nmedio") +
  scale_fill_gradient(low = "white", high = "#00FFFF", n.breaks = 5)

plot2 <- ggplot() +
  geom_sf(data = mundocol) +
  geom_sf(data = mapdeptos, aes(fill = IP2018), col = "darkgray", linetype = "solid") +
  coord_sf(xlim = c(box$xmin, box$xmax), ylim = c(box$ymin, box$ymax), expand = FALSE) +
  geom_sf_text(data = mapdeptos, aes(label = ifelse(IP2018 > quantile(IP2018, probs = 0.90, na.rm = TRUE), DPTO_CNMBR, "")), col = "black",
               fontface = "bold", size = 2, fun.geometry = function(x) sf::st_centroid(x)) +
  labs(x = "Longitud", y = "Latitud", title = "Índice de pobreza \npor departamento en\n2018", fill = "Índice de \n pobreza" ) +
  scale_fill_gradient(low = "white", high = "#FFD700", n.breaks = 5)

```

```{r}
library(gridExtra)
grid.arrange(plot1, plot2, ncol = 2)
```

## Punto 2

```{r}
library(readr)
library(stringr)
estadisticas_edu <- read_delim("C:/Bayesiana/Caso2/estadísticas_educación.csv",delim = ",")

  estadisticas_edu <- estadisticas_edu %>%
  filter(AÑO == 2022) %>%
  select(AÑO,CÓDIGO_MUNICIPIO,MUNICIPIO,CÓDIGO_DEPARTAMENTO,DEPARTAMENTO,COBERTURA_NETA_SECUNDARIA) %>%
  as.data.frame()

punt_muestrales_mpios <- datos %>%
  group_by(COLE_COD_MCPIO_UBICACION) %>%
  summarise(puntmedio = mean(PUNT_GLOBAL)) %>%
  as.data.frame()

punt_muestrales_mpios$COLE_COD_MCPIO_UBICACION <- sub("^00", "0", punt_muestrales_mpios$COLE_COD_MCPIO_UBICACION)

Mapa_mpios <- punt_muestrales_mpios %>%
  full_join(estadisticas_edu,by = c("COLE_COD_MCPIO_UBICACION"="CÓDIGO_MUNICIPIO"))%>%
  as.data.frame()


```


```{r}
mpioshp <- st_read("C:/Bayesiana/Caso2/misc/MGN_MPIO_POLITICO.shp",quiet=TRUE) 
mpioshp$MPIO_COD <- paste(mpioshp$DPTO_CCDGO,mpioshp$MPIO_CCDGO,sep = "")

mapmpios <- mpioshp %>%
  left_join(Mapa_mpios,by=c("MPIO_COD"="COLE_COD_MCPIO_UBICACION")) 

mundoshp <- st_read("C:/Bayesiana/Caso2/misc/admin00.shp",quiet=TRUE)
mundocol <- mundoshp %>% 
            filter(CNTRY_NAME %in% c("Peru","Brazil","Venezuela","Ecuador","Panama"))
```

```{r}
box2 <- st_bbox(mapmpios)
plot3 <- ggplot() +
  geom_sf(data = mundocol) +
  geom_sf(data = mapmpios, aes(fill = puntmedio), col = "gray", linetype = "solid", size=0.001) +
  coord_sf(xlim = c(box2$xmin, box2$xmax), ylim = c(box2$ymin, box2$ymax), expand = FALSE) +
  labs(x = "Longitud", y = "Latitud", title = "Puntaje medio en las \npruebas Saber Pro \npor municipio en 2022-II", fill = "Puntaje \nmedio") +
  scale_fill_gradient(low = "white", high = "#00FFFF", n.breaks = 5)


plot4 <- ggplot() +
  geom_sf(data = mundocol) +
  geom_sf(data = mapmpios, aes(fill = COBERTURA_NETA_SECUNDARIA), col = "gray", linetype =  "solid", size=0.001) +
  coord_sf(xlim = c(box2$xmin, box2$xmax), ylim = c(box2$ymin, box2$ymax), expand = FALSE) +
  labs(x = "Longitud", y = "Latitud", title = "Cobertura neta \nsecundaria por municipio \nen 2022", fill = "Cob. \nneta \nsec." ) +
  scale_fill_gradient(low = "white", high = "#00CD00", n.breaks = 5)
```


```{r}
grid.arrange(plot3, plot4, ncol = 2)
```



## Implemetación de los modelos

###MODELO 1, modelo normal
```{r Implementación Modelos}
#B total de iteraciones para el muestreador
#y vector de puntajes
#Hiperparametros
#mu0
#gamma0
#nu0
#s20
mod1 <- function(B,y,mu0,gamma0,nu0,s20){
  #tamaños
  n <- length(y)
  ybar <- mean(y)
  ysum <- sum(y)
  s2 <- var(y)
  
  #valores inicales
  sig2 <- 1/rgamma(n = 1,shape = nu0/2,rate = (nu0*s20)/2)
  
  #calculos previos 
  invgamma0 <- 1/gamma0
  mu0_gamma0 <- mu0/gamma0
  nun_2 <- (n + nu0)/2
  nun <- n+nu0
  nu0xs20 <- nu0*s20
  
  cont <- 1
  #almacenamiento
  THETA <- matrix(data = NA, nrow = (B-1000)/10, ncol = 2)
  LL <- matrix(data = NA, nrow = (B-1000)/10, ncol = 1)
  
  #cadena
  for (b in 1:B) {
    #actualizar theta
    vtheta <- 1/(n/sig2+invgamma0)
    theta <- rnorm(n = 1, mean = (ysum/sig2 + mu0_gamma0)*vtheta, sd = sqrt(vtheta))
    
    #actualizar sigma^2
    sig2 <- 1/rgamma(n = 1, shape =  nun_2, rate = 0.5*(nu0xs20+(n-1)*s2+n*(ybar-theta)^2))
    
    
    if(b > 1000 &&  (b - 1000) %% 10 == 0){
    #almacenar valores
     THETA[cont,] <-  c(theta,sig2)
    #Log-verosimilitud
     LL[cont] <- sum(dnorm(x = y, mean = theta, sd = sqrt(sig2),log = TRUE))
     
     cont <- cont+1
    }
  }
  
  #fin de la cadena
  colnames(THETA) <- c("theta","sig2")
  colnames(LL) <- c("ll")

  #salida
  THETA <- as.data.frame(THETA)
  LL <- as.data.frame(LL)
  return(list(THETA = THETA,LL = LL))
}
```

```{r calculo modelo 1}
#Hiperparametros
y <- datos$PUNT_GLOBAL
mu0 <- 250
gamma0 <- 50^2
nu0 <- 1 
s20 <- 50^2

tictoc::tic()
set.seed(1203)
chain1 <- mod1(B = 101000, y = y,mu0 = mu0,gamma0 = gamma0, nu0 = nu0, s20 = s20)
tictoc::toc()
```

### Pruebas de convergencia (gráficas)
```{r, graficas cadena 1}
plot(x = 1:10000, y =  unlist(chain1$LL),type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud")
plot(chain1$THETA[,1],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta))
plot(chain1$THETA[,2],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma^2))

#La logverosimilitud parece que convergen apropiadamente.
```
### Pruebas de convergencia (Tamaño efectivo de Muestra, Error estándar de Montecarlo, Coeficiente del error de Montecarlo)
```{r}
#tamaño efectivo de muestra
(neff_THETA_1 <- coda::effectiveSize(chain1$THETA))

#error estandar de Monte Carlo
EMC_1 <- apply(X = chain1$THETA, MARGIN = 2, FUN = sd)/sqrt(neff_THETA_1)

#coeficiente de variación de Monte Carlo (%)
CVMC_1 <- 100*abs(EMC_1/colMeans(chain1$THETA))
(round(CVMC_1,digits=4))
```

## Modelo 2(Modelo jerárquico Normal con medias específicas)
```{r}
mod2 <- function(B,nj,yb,s2,mu0, g20, eta0, t20, nu0, s20){
  #tamaño 
  n <- sum(nj)
  m <- length(nj)
  
  #valores inciales
  theta <- yb
  sig2  <- mean(s2)
  mu    <- mean(theta)
  tau2  <- var(theta)
  
  #calculos previos
  invg20 <- 1/g20
  mu0_g20 <- mu0/g20
  eta0_m <- eta0+m
  #almacenamiento
  THETA <- matrix(data = NA, nrow = (B-1000)/10, ncol = m+3)
  LL    <- matrix(data = NA, nrow = (B-1000)/10, ncol = 1)
  
  cont <- 1
  #cadena
  for (b in 1:B) {
    #actualizar theta
    vtheta <- 1/(1/tau2 + nj/sig2)
    theta  <- rnorm(n = m, mean = vtheta*(mu/tau2 + nj*yb/sig2), sd = sqrt(vtheta))
    
    #actualizar sigma^2
    sig2 <- 1/rgamma(n = 1, shape = 0.5*(nu0 + n), rate = 0.5*(nu0*s20 + sum((nj-1)*s2 + nj*(yb - theta)^2)))
    
    # actualizar mu
    vmu <- 1/(invg20 + m/tau2)
    mu  <- rnorm(n = 1, mean = vmu*(mu0_g20 + m*mean(theta)/tau2), sd = sqrt(vmu)) 
    
    # actualizar tau^2
    tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0_m), rate = 0.5*(eta0*t20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
    
    #Almacenar valores
    if(b > 1000 &&  (b - 1000) %% 10 == 0){
    #almacenar valores
     THETA[cont,] <-  c(theta, sig2, mu, tau2)
    #Log-verosimilitud
     LL[cont] <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(sig2), log = T))
     
     cont <- cont+1
    }
  }
  #fin de la cadena
  colnames(THETA) <- c(paste0("theta",1:m), "sig2", "mu", "tau2")
  colnames(LL) <- c("ll")
  THETA <- as.data.frame(THETA)
  LL    <- as.data.frame(LL)
  return(list(THETA = THETA, LL = LL))
}
```

```{r calculo de la cadena 2}
# tratamiento de datos
# y  : puntaje de los estudiantes (c)
# Y  : puntaje de los estudiantes (list)
# g  : identificador secuencial de los departamentos (c)
# nj : número de estudiantes por departamento (c)
# yb : promedios por departamento (c)
# s2 : varianzas por departamento (c)
m <- length(table(datos$COLE_COD_DEPTO_UBICACION))
y <- datos$PUNT_GLOBAL
Y <- vector(mode = "list", length = m)

estadisticos <- datos %>% 
  group_by(COLE_COD_DEPTO_UBICACION) %>% 
  summarise(codigo = unique(COLE_COD_DEPTO_UBICACION), 
            nombre = unique(COLE_DEPTO_UBICACION), 
            nj = n(), 
            yb = mean(PUNT_GLOBAL), 
            s2 = var(PUNT_GLOBAL))

nj <- estadisticos$nj
yb <- estadisticos$yb
s2 <- estadisticos$s2

# hiperparámetros
mu0  <- 250 
g20  <- 50^2
eta0 <- 1
t20  <- 50^2
nu0  <- 1
s20  <- 50^2

tictoc::tic()
set.seed(2023)
chain2 <- mod2(B = 101000, nj, yb, s2, mu0, g20, eta0, t20, nu0, s20)
tictoc::toc()
```

### Pruebas de convergencia (gráficas)
```{r, graficas cadena 2}
plot(x = 1:10000, y =  unlist(chain2$LL),type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud")

#seleccionaremos 5 thetas al azar.
set.seed(101)
sample(1:m, 5, replace = FALSE)
#los thetas seleccionados son: 9 25 14 23 17

plot(chain2$THETA[,9], type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[9]))
plot(chain2$THETA[,25],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[25]))
plot(chain2$THETA[,14],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[14]))
plot(chain2$THETA[,23],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[23]))
plot(chain2$THETA[,17],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[17]))

#ahora veremos los otros parámetros 
plot(chain2$THETA[,m+1],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma^2))
plot(chain2$THETA[,m+2],type = "p", pch = ".", xlab = "Iteración", ylab = expression(mu))
plot(chain2$THETA[,m+3],type = "p", pch = ".", xlab = "Iteración", ylab = expression(tau^2))
```
### Pruebas de convergencia (Tamaño efectivo de Muestra, Error estándar de Montecarlo, Coeficiente del error de Montecarlo)
```{r}
neff_THETA_2 <- coda::effectiveSize(chain2$THETA[1:m])
(summary(neff_THETA_2))
(neff_OTROS_2 <- coda::effectiveSize(chain2$THETA[(m+1):(m+3)]))

#error estandar de Monte Carlo
EMC_THETA_2 <- apply(X = chain2$THETA[1:m], MARGIN = 2, FUN = sd)/sqrt(neff_THETA_2)
EMC_OTROS_2 <- apply(X = chain2$THETA[(m+1):(m+3)], MARGIN = 2, FUN = sd)/sqrt(neff_OTROS_2)

#coeficiente de variación de Monte Carlo (%)
CVMC_THETA_2 <- 100*abs(EMC_THETA_2/colMeans(chain2$THETA[1:m]))
CVMC_OTROS_2 <- 100*abs(EMC_OTROS_2/colMeans(chain2$THETA[(m+1):(m+3)]))
(summary(round(CVMC_THETA_2,digits = 4)))
(round(CVMC_OTROS_2,digits = 4))
```

### Modelo 3, Modelo jerárquico Normal con medias y varianzas específicas 
```{r cadena3}
mod3 <- function(B, nj, yb, s2, mu0, g20, eta0, t20,al0, be0,nu) {
  # tamaños
  n <- sum(nj)
  m <- length(nj)
  
  # valores iniciales
  theta <- yb
  sig2  <- s2  # sigma_j^2
  mu    <- mean(theta)
  tau2  <- var(theta)
  ups2  <- rgamma(n = 1,shape = al0*0.5,rate = be0*0.5)  # sigma^2
  
  #calculos previos
  invg20 <- 1/g20
  mu0_g20 <- mu0/g20
  eta0_m <- eta0+m
  etaxt20 <- eta0*t20 
  a <- (al0 + m*nu)*0.5
  
  cont <- 1
  # almacenamiento
  THETA <- matrix(data = NA, nrow = (B-1000)/10, ncol = 2*m+3)
  LL    <- matrix(data = NA, nrow = (B-1000)/10, ncol = 1)
  
  # cadena
  for (b in 1:B) {
    # actualizar theta
    vtheta <- 1/(1/tau2 + nj/sig2)
    theta  <- rnorm(n = m, mean = vtheta*(mu/tau2 + nj*yb/sig2), sd = sqrt(vtheta))
    
    # actualizar sigma_j^2
    sig2 <- 1/rgamma(n = m, shape = 0.5*(nu + nj), rate = 0.5*(nu*ups2 + (nj-1)*s2 + nj*(yb - theta)^2))
    
    # actualizar mu
    vmu <- 1/(invg20 + m/tau2)
    mu  <- rnorm(n = 1, mean = vmu*(mu0_g20 + m*mean(theta)/tau2), sd = sqrt(vmu))
    
    # actualizar tau2
    tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0_m), rate = 0.5*(etaxt20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
    
    # actualizar sigma^2
    ups2 <- rgamma(n = 1, shape = a, rate = (be0 + nu*sum(1/sig2))*0.5)
  
    # almacenar
    if(b > 1000 && (b - 1000) %% 10 == 0){
    THETA[cont,] <- c(theta, sig2, mu, tau2, ups2)
    # log-verosimilitud
    LL[cont] <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(rep(sig2, nj)), log = T))
    cont <- cont+1
    }
  }
  
  # fin de la cadena
  # salida
  colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m), "mu", "tau2", "ups2")
  colnames(LL) <- c("ll")
  THETA <- as.data.frame(THETA)
  LL    <- as.data.frame(LL)
  return(list(THETA = THETA, LL = LL))
}
```


```{r calculo de la cadena3}
m <- length(table(datos$COLE_COD_DEPTO_UBICACION))

y <- datos$PUNT_GLOBAL

Y <- vector(mode = "list", length = m)

estadisticos <- datos %>% 
  group_by(COLE_COD_DEPTO_UBICACION) %>% 
  summarise(codigo = unique(COLE_COD_DEPTO_UBICACION), 
            nombre = unique(COLE_DEPTO_UBICACION), 
            nj = n(), 
            yb = mean(PUNT_GLOBAL), 
            s2 = var(PUNT_GLOBAL))

nj <- estadisticos$nj
yb <- estadisticos$yb
s2 <- estadisticos$s2

# hiperparámetros
  mu0  <- 250 
  g20  <- 50^2
  eta0 <- 1  
  t20  <- 50^2
  nu <- 1
  al0  <- 1
  be0  <- 1/50^2 

tictoc::tic()
set.seed(2023)
chain3 <- mod3(B = 101000, nj, yb, s2, mu0, g20, eta0, t20,al0,be0,nu)
tictoc::toc()
```

### Pruebas de convergencia (gráficas)
```{r, graficas cadena 3}
plot(x = 1:10000, y =  unlist(chain3$LL),type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud")
#Escogeremos 5 valores de theta al azar
set.seed(1001)
(sample(1:m,5,replace = FALSE))
#Los thetas escogidos fueron 23 3 32 15 16
plot(chain3$THETA[,23],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[23]))
plot(chain3$THETA[,3],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[3]))
plot(chain3$THETA[,32],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[32]))
plot(chain3$THETA[,15],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[15]))
plot(chain3$THETA[,16],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[16]))

#Escogeremos 5 valores al azar, para graficar los sigma^2
set.seed(1002)
(sample((m+1):(2*m),5,replace = FALSE))-m
#los valores de sigma a mostrar son 12  9 15 29  7 o (44 41 47 61 39)
plot(chain3$THETA[,44],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma[12]^2))
plot(chain3$THETA[,41],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma[9]^2))
plot(chain3$THETA[,47],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma[15]^2))
plot(chain3$THETA[,61],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma[29]^2))
plot(chain3$THETA[,39],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma[7]^2))

plot(chain3$THETA$tau2,type = "p", pch = ".", xlab = "Iteración", ylab = expression(tau))
plot(chain3$THETA$mu,type = "p", pch = ".", xlab = "Iteración", ylab = expression(mu))
plot(chain3$THETA$ups2,type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma^2))
```
### Pruebas de convergencia (Tamaño efectivo de Muestra, Error estándar de Montecarlo, Coeficiente del error de Montecarlo)
```{r}
neff_THETA_3 <- coda::effectiveSize(chain3$THETA[1:m])
neff_SIG_3 <- coda::effectiveSize(chain3$THETA[(m+1):(2*m)])
(summary(neff_THETA_3))
(summary(neff_SIG_3))
(neff_OTROS_3 <- coda::effectiveSize(chain3$THETA[(2*m+1):(2*m+3)]))

#error estandar de Monte Carlo
EMC_THETA_3 <- apply(X = chain3$THETA[1:m], MARGIN = 2, FUN = sd)/sqrt(neff_THETA_3)
EMC_SIG_3 <- apply(X = chain3$THETA[(m+1):(2*m)], MARGIN = 2, FUN = sd)/sqrt(neff_SIG_3)
EMC_OTROS_3 <- apply(X = chain3$THETA[(2*m+1):(2*m+3)], MARGIN = 2, FUN = sd)/sqrt(neff_OTROS_3)

#coeficiente de variación de Monte Carlo (%)
CVMC_THETA_3 <- 100*abs(EMC_THETA_3/colMeans(chain3$THETA[1:m]))
CVMC_SIG_3 <- 100*abs(EMC_SIG_3/colMeans(chain3$THETA[(m+1):(2*m)]))
CVMC_OTROS_3 <- 100*abs(EMC_OTROS_3/colMeans(chain3$THETA[(2*m+1):(2*m+3)]))
(summary(round(CVMC_THETA_3,digits = 4)))
(summary(round(CVMC_SIG_3,digits = 4)))
(round(CVMC_OTROS_3,digits = 4))
```

### Modelo 4, Modelo Normal con medias específicas por municipio y departamento
```{r}
mod4 <- function(B,njk,ybjk,s2jk,nk,xi0,k20,mu0,g20,eta0,tau20,nu0,s20){
#tamaños 
  N <- sum(njk)
  lennjk <- length(njk)
  sumnk <- sum(nk)
  m <- length(nk)

#valores inciales
  k2 <- 1/rgamma(n = 1, shape = xi0*0.5,rate = (xi0*k20)*0.5)
  mu <- rnorm(n = 1, mean = mu0,sd = sqrt(s20))
  tau2 <- 1/rgamma(n = 1, shape = eta0*0.5,rate = (eta0*tau20)*0.5)
  sig2 <- 1/rgamma(n=1, shape = nu0*0.5,rate = (nu0*s20)*0.5)
  theta <- rnorm(n = m, mean = mu, sd = sqrt(tau2))
#calculos previos
  xi0xk20  <- xi0*k20
  N_xi0 <- N+xi0
  invg20 <- 1/g20
  mu0_g20 <- mu0/g20
  m_eta0_2 <- 0.5*(m+eta0)
  eta0xtau20 <- eta0*tau20
  sumnk_nu0 <- sumnk+nu0 
  nu0xs20 <- nu0*s20

  cont <- 1
  
  #Almacenamiento
  ZETA <- matrix(data = NA, nrow = (B-1000)/10, ncol = lennjk)
  THETA <- matrix(data = NA,nrow = (B-1000)/10, ncol = m)
  OTROS <- matrix(data = NA, nrow = (B-1000)/10,ncol =  4)
  LL    <- matrix(data = NA, nrow = (B-1000)/10, ncol = 1)
  
  for (b in 1:B) {
    #actualizar zeta
    vzeta <- 1/(njk/k2 + 1/sig2)
    zeta <- rnorm(n = lennjk ,mean = vzeta*((njk*ybjk)/k2+rep(theta,nk)/sig2),sd = sqrt(vzeta))
    
    zetabar <- tapply(zeta, rep(1:m, times = nk), FUN = mean)
    vzeta <- tapply(zeta, rep(1:m, times = nk), FUN = var)
    vzeta[3] <- (zeta[149]-theta[3])^2
    
    #actualizar kappa^2
    k2 <- 1/rgamma(n = 1, shape = 0.5*(N_xi0),rate = 0.5*(xi0xk20 + sum((njk-1)*s2jk+njk*(ybjk-zeta)^2)))
    
    #actualizar theta
    vtheta <- 1/(nk/sig2+1/tau2)
    theta <- rnorm(n = m,mean = vtheta*((nk*zetabar)/sig2+mu/tau2),sd=sqrt(vtheta))
    
    thetabar <- mean(theta)
    stheta <- var(theta)
    
    #actualizar mu 
    vmu <- 1/(m/tau2 + invg20)
    mu <- rnorm(n=1, mean = vmu*((m*thetabar)/tau2+mu0_g20), sd = sqrt(vmu))
    
    #actualizar tau^2
    tau2 <- 1/rgamma(n = 1,shape = m_eta0_2,rate = 0.5*(eta0xtau20+(m-1)*stheta+m*(thetabar-mu)^2))
    
    #actualizar sig2
    sig2 <- 1/rgamma(n = 1,shape = 0.5*sumnk_nu0,rate = 0.5*(nu0xs20+sum((nk-1)*vzeta + nk*(zetabar-theta)^2)))
    
    if((b - 1000) %% 10 == 0 && b > 1000){
      ZETA[cont,] <- zeta
      THETA[cont,] <- theta
      OTROS[cont,] <- c(k2,mu,tau2,sig2)
      LL[cont] <- sum(dnorm(x = y, mean = rep(zeta, njk), sd = sqrt(k2), log = T))
      cont <- cont+1
    }
  }
  #colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m), "mu", "tau2", "ups2")
  colnames(ZETA) <- c(paste0("zeta",1:lennjk))
  colnames(THETA) <- c(paste0("theta",1:m))
  colnames(OTROS) <- c("k2","mu","tau2","sig2")
  colnames(LL) <- c("ll")
  
  ZETA <- as.data.frame(ZETA)
  THETA <- as.data.frame(THETA)
  OTROS <- as.data.frame(OTROS)
  LL <- as.data.frame(LL)
  
  return(list(ZETA = ZETA,THETA = THETA,OTROS = OTROS,LL = LL))
}
```


```{r, definimos hiperparametros}
estadisticas_mpios <- datos %>%
  mutate(COLE_COD_MCPIO_UBICACION = ifelse(substr(COLE_COD_MCPIO_UBICACION, 1, 1) == "0", substr(COLE_COD_MCPIO_UBICACION, 2, nchar(COLE_COD_MCPIO_UBICACION)), COLE_COD_MCPIO_UBICACION)) %>%
  group_by(COLE_COD_MCPIO_UBICACION) %>%
  summarise(codigo = unique(COLE_COD_MCPIO_UBICACION),
            nombre = unique(COLE_MCPIO_UBICACION),
            njk = n(),
            ybjk = mean(PUNT_GLOBAL),
            s2jk = var(PUNT_GLOBAL)) %>%
  arrange(codigo)

estadisticas_mpios <- estadisticas_mpios %>%
  mutate(COD_DEPARTAMENTO = substr(COLE_COD_MCPIO_UBICACION, 1, 2))

conteo_deptos <- estadisticas_mpios %>%
  group_by(COD_DEPARTAMENTO) %>%
  summarise(codigo = unique(COD_DEPARTAMENTO),
            nk = n())

nk <- conteo_deptos$nk

estadisticas_deptos <- datos %>%
  group_by(COLE_COD_DEPTO_UBICACION) %>%
  summarise(codigo = unique(COLE_COD_DEPTO_UBICACION),
            nombre = unique(COLE_DEPTO_UBICACION),
            nk = n(),
            ybk = mean(PUNT_GLOBAL),
            s2k = var(PUNT_GLOBAL))%>%
  arrange(COLE_COD_DEPTO_UBICACION)

njk <- estadisticas_mpios$njk
ybjk <- estadisticas_mpios$ybjk
s2jk <- estadisticas_mpios$s2jk

#hiperparametros
B <- 101000
xi0 <- 1
k20 <- 50^2
mu0 <- 250
g20 <- 50^2
eta0 <- 1
tau20 <- 50^2
nu0 <- 1
s20 <- 50^2
y<-datos$PUNT_GLOBAL
```

```{r calculo de la cadena 4}
tictoc::tic()
set.seed(2023)
chain4 <- mod4(B,njk,ybjk,s2jk,nk,xi0,k20,mu0,g20,eta0,tau20,nu0,s20)
tictoc::toc()
```
### Pruebas de convergencia (gráficas)
```{r}
plot(x = 1:10000, y =  unlist(chain4$LL),type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud")

##elegimos 5 zeta al azar
set.seed(1003)
sample(1:length(njk),5,replace = FALSE)
#los zeta elegidos fueron 217,102,629,1029,940
plot(chain4$ZETA[,217],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[217]))
plot(chain4$ZETA[,102],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[102]))
plot(chain4$ZETA[,629],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[629]))
plot(chain4$ZETA[,1029],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[1029]))
plot(chain4$ZETA[,940],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[940]))

#elegimos 3 thetas añ azar
set.seed(1004)
sample(1:m,3,replace = FALSE)
#los thetas a graficar son 11,24,22
plot(chain4$THETA[,11],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[11]))
plot(chain4$THETA[,4],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[24]))
plot(chain4$THETA[,4],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[22]))

plot(chain4$OTROS[,1],type = "p", pch = ".", xlab = "Iteración", ylab = expression(kappa))
plot(chain4$OTROS[,2],type = "p", pch = ".", xlab = "Iteración", ylab = expression(mu))
plot(chain4$OTROS[,3],type = "p", pch = ".", xlab = "Iteración", ylab = expression(tau))
plot(chain4$OTROS[,4],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma))
```
### Pruebas de convergencia (Tamaño efectivo de Muestra, Error estándar de Montecarlo, Coeficiente del error de Montecarlo)
```{r}
#Tamaños efectivos de muestra
neff_ZETA_4 <- coda::effectiveSize(chain4$ZETA)
neff_THETA_4 <- coda::effectiveSize(chain4$THETA)
(summary(neff_ZETA_4))
(summary(neff_THETA_4))
(neff_OTROS_4 <- coda::effectiveSize(chain4$OTROS))

#error estandar de Monte Carlo
EMC_ZETA_4 <- apply(X = chain4$ZETA, MARGIN = 2, FUN = sd)/sqrt(neff_ZETA_4)
EMC_THETA_4 <- apply(X = chain4$THETA, MARGIN = 2, FUN = sd)/sqrt(neff_THETA_4)
EMC_OTROS_4 <- apply(X = chain4$OTROS, MARGIN = 2, FUN = sd)/sqrt(neff_OTROS_4)

#coeficiente de variación de Monte Carlo (%)
CVMC_ZETA_4 <- 100*abs(EMC_ZETA_4/colMeans(chain4$ZETA))
CVMC_THETA_4 <- 100*abs(EMC_THETA_4/colMeans(chain4$THETA))
CVMC_OTROS_4 <- 100*abs(EMC_OTROS_4/colMeans(chain4$OTROS))

(summary(round(CVMC_ZETA_4,digits = 4)))
(summary(round(CVMC_THETA_4,digits = 4)))
(round(CVMC_OTROS_4,digits = 4))
```

### Modelo 5,Modelo Normal con medias y varianzas específicas por municipio y departamento
```{r}
mod5 <- function(B,njk,ybjk,s2jk,nk,xi0,k20,mu0,g20,tau20,eta0,nu,al0,be0){
  
  #tamaños
  N <- sum(njk)
  lennjk <- length(njk)
  sumnk <- sum(nk)
  m <- length(nk)
  
  #valores iniciales
  
  k2 <- 1/rgamma(n = 1, shape = xi0*0.5,rate = (xi0*k20)*0.5)
  mu <- rnorm(n = 1, mean = mu0,sd = sqrt(s20))
  tau2 <- 1/rgamma(n = 1, shape = eta0*0.5,rate = (eta0*tau20)*0.5)
  ups <- rgamma(n = 1, shape = al0*0.5 , rate = be0*0.5)
  theta <- rnorm(n = m, mean = mu, sd = sqrt(tau2))
  sig2 <- 1/rgamma(n = m, shape = nu,rate = ups)
  
  
  #calculos previos
  xi0xk20  <- xi0*k20
  N_xi0 <- N+xi0
  invg20 <- 1/g20
  mu0_g20 <- mu0/g20
  m_eta0_2 <- 0.5*(m+eta0)
  eta0xtau20 <- eta0*tau20
  nk_nu <- nk + nu
  nu_al0_2 <- 0.5*(m*nu+al0)
  
  cont <- 1
  
  #almacenamiento
  ZETA <- matrix(data = NA, nrow = (B-1000)/10, ncol = lennjk)
  THETA <- matrix(data = NA,nrow = (B-1000)/10, ncol = m)
  SIG2 <- matrix(data = NA,nrow = (B-1000)/10, ncol = m)
  OTROS <- matrix(data = NA, nrow = (B-1000)/10,ncol =  4)
  LL    <- matrix(data = NA, nrow = (B-1000)/10, ncol = 1)
  
  for (b in 1:B) {
    #actualizar zeta
    vzeta <- 1/(njk/k2 + 1/rep(sig2,nk))
    zeta <- rnorm(n = lennjk, mean = vzeta*((njk*ybjk)/k2+rep(theta,nk)/rep(sig2,nk)),sd = sqrt(vzeta))
    
    zeta_bar <- tapply(zeta, rep(1:m, times = nk), FUN = mean)
    var_zeta <- tapply(zeta, rep(1:m, times = nk), FUN = var)
    var_zeta[3] <- (zeta[149]-theta[3])^2
    
    #actualizar k2
    k2 <- 1/rgamma(n = 1, shape = 0.5*(N_xi0),rate = 0.5*(xi0xk20 + sum((njk-1)*s2jk+njk*(ybjk-zeta)^2)))
    
    #actualizar theta 
    vtheta <- 1/(nk/sig2+1/tau2)
    theta <- rnorm(n = m,mean = vtheta*((nk*zeta_bar)/sig2+mu/tau2),sd=sqrt(vtheta))
    
    theta_bar <- mean(theta)
    var_theta <- var(theta)
    
    #actualizar mu
    vmu <- 1/(m/tau2 + invg20)
    mu <- rnorm(n=1, mean = vmu*((m*theta_bar)/tau2+mu0_g20), sd = sqrt(vmu))
    
    #actualizar tau2
    tau2 <- 1/rgamma(n = 1,shape = m_eta0_2,rate = 0.5*(eta0xtau20+(m-1)*var_theta+m*(theta_bar-mu)^2))
    
    #actualizar sig2
    sig2 <- 1/rgamma(n = m, shape = 0.5*(nk_nu),rate = 0.5*(nu*ups+(nk-1)*var_zeta + nk*(zeta_bar-theta)^2))
    
    #actualizar ups
    ups <- rgamma(n = 1, shape = nu_al0_2,rate = 0.5*(be0+nu*sum(1/sig2)))
    
    if((b - 1000) %% 10 == 0 && b > 1000){
      ZETA[cont,] <- zeta
      THETA[cont,] <- theta
      SIG2[cont,] <- sig2
      OTROS[cont,] <- c(k2,mu,tau2,ups)
      LL[cont] <- sum(dnorm(x = y, mean = rep(zeta, njk), sd = sqrt(k2), log = T))
      cont <- cont+1
    }
  }
  
  colnames(ZETA) <- c(paste0("zeta",1:lennjk))
  colnames(THETA) <- c(paste0("theta",1:m))
  colnames(SIG2) <- c(paste0("sig2",1:m))
  colnames(OTROS) <- c("k2","mu","tau2","ups")
  colnames(LL) <- c("ll")
  
  ZETA <- as.data.frame(ZETA)
  THETA <- as.data.frame(THETA)
  SIG2 <- as.data.frame(SIG2)
  OTROS <- as.data.frame(OTROS)
  LL <- as.data.frame(LL)
  
  
  return(list(ZETA = ZETA,THETA = THETA,SIG2 = SIG2,OTROS = OTROS,LL = LL))
}
```

```{r hiperparametros}
estadisticas_mpios <- datos %>%
  mutate(COLE_COD_MCPIO_UBICACION = ifelse(substr(COLE_COD_MCPIO_UBICACION, 1, 1) == "0", substr(COLE_COD_MCPIO_UBICACION, 2, nchar(COLE_COD_MCPIO_UBICACION)), COLE_COD_MCPIO_UBICACION)) %>%
  group_by(COLE_COD_MCPIO_UBICACION) %>%
  summarise(codigo = unique(COLE_COD_MCPIO_UBICACION),
            nombre = unique(COLE_MCPIO_UBICACION),
            njk = n(),
            ybjk = mean(PUNT_GLOBAL),
            s2jk = var(PUNT_GLOBAL)) %>%
  arrange(codigo)

estadisticas_mpios <- estadisticas_mpios %>%
  mutate(COD_DEPARTAMENTO = substr(COLE_COD_MCPIO_UBICACION, 1, 2))

conteo_deptos <- estadisticas_mpios %>%
  group_by(COD_DEPARTAMENTO) %>%
  summarise(codigo = unique(COD_DEPARTAMENTO),
            nk = n())

nk <- conteo_deptos$nk

estadisticas_deptos <- datos %>%
  group_by(COLE_COD_DEPTO_UBICACION) %>%
  summarise(codigo = unique(COLE_COD_DEPTO_UBICACION),
            nombre = unique(COLE_DEPTO_UBICACION),
            nk = n(),
            ybk = mean(PUNT_GLOBAL),
            s2k = var(PUNT_GLOBAL))%>%
  arrange(COLE_COD_DEPTO_UBICACION)

njk <- estadisticas_mpios$njk
ybjk <- estadisticas_mpios$ybjk
s2jk <- estadisticas_mpios$s2jk

ybd <- estadisticas_deptos$ybk
s2d <- estadisticas_deptos$s2k

#B,njk,ybjk,s2jk,nk,ybd,s2d,xi0,k20,mu0,g20,tau20,eta0,nu,al0,be0
#hiperparametros
B <- 101000
xi0 <- 1
k20 <- 50^2
mu0 <- 250
g20 <- 50^2
eta0 <- 1
tau20 <- 50^2
nu <- 1
al0 <- 1
be0 <- 1/50^2
y<-datos$PUNT_GLOBAL
```

```{r, calculo de la cadena 5}
tictoc::tic()
set.seed(2023) 
chain5 <- mod5(B,njk,ybjk,s2jk,nk,xi0,k20,mu0,g20,tau20,eta0,nu,al0,be0)
tictoc::toc()
```

### Pruebas de convergencia (gráficas)
```{r}
plot(x = 1:10000, y =  unlist(chain5$LL),type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud")

#elegiremos 5 zetas para graficar de manera aleatoria
set.seed(1005)
sample(1:length(njk),5,replace = FALSE)
#los zetas a graficas son 1049  562 1008  329  44

plot(chain5$ZETA[,1049],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[1049]))
plot(chain5$ZETA[,562],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[562]))
plot(chain5$ZETA[,1008],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[1008]))
plot(chain5$ZETA[,329],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[329]))
plot(chain5$ZETA[,445],type = "p", pch = ".", xlab = "Iteración", ylab = expression(zeta[445]))

#elegiremos 3 thetas para graficar de manera aleatoria
set.seed(1006)
sample(1:m,3,replace = FALSE)
#los thetas a graficar son 28  5 20

plot(chain5$THETA[,28],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[28]))
plot(chain5$THETA[,5],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[5]))
plot(chain5$THETA[,20],type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta[20]))

#elegiremos 3 sigmas para graficar de manera aleatoria
set.seed(1007)
sample(1:m,3,replace = FALSE)
#los sigmas a graficar son 3 19  5
plot(chain5$SIG2[,3],type = "p",pch = ".",xlab = "Iteración",ylab = expression(sigma[3]^2))
plot(chain5$SIG2[,19],type = "p",pch = ".",xlab = "Iteración",ylab = expression(sigma[19]^2))
plot(chain5$SIG2[,5],type = "p",pch = ".",xlab = "Iteración",ylab = expression(sigma[5]^2))

plot(chain5$OTROS[,1],type = "p", pch = ".", xlab = "Iteración", ylab = expression(kappa^2))
plot(chain5$OTROS[,2],type = "p", pch = ".", xlab = "Iteración", ylab = expression(mu))
plot(chain5$OTROS[,3],type = "p", pch = ".", xlab = "Iteración", ylab = expression(tau^2))
plot(chain5$OTROS[,4],type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma^2))
```
### Pruebas de convergencia (Tamaño efectivo de Muestra, Error estándar de Montecarlo, Coeficiente del error de Montecarlo)
```{r}
#Tamaños efectivos de muestra
neff_ZETA_5 <- coda::effectiveSize(chain5$ZETA)
neff_THETA_5 <- coda::effectiveSize(chain5$THETA)
neff_SIG_5 <- coda::effectiveSize(chain5$SIG2)
(summary(neff_ZETA_5))
(summary(neff_THETA_5))
(summary(neff_SIG_5))
(neff_OTROS_5 <- coda::effectiveSize(chain5$OTROS))

#error estandar de Monte Carlo
EMC_ZETA_5 <- apply(X = chain5$ZETA, MARGIN = 2, FUN = sd)/sqrt(neff_ZETA_5)
EMC_THETA_5 <- apply(X = chain5$THETA, MARGIN = 2, FUN = sd)/sqrt(neff_THETA_5)
EMC_SIG_5 <- apply(X = chain5$SIG2, MARGIN = 2, FUN = sd)/sqrt(neff_SIG_5)
EMC_OTROS_5 <- apply(X = chain5$OTROS, MARGIN = 2, FUN = sd)/sqrt(neff_OTROS_5)

#coeficiente de variación de Monte Carlo (%)
CVMC_ZETA_5 <- 100*abs(EMC_ZETA_5/colMeans(chain5$ZETA))
CVMC_THETA_5 <- 100*abs(EMC_THETA_5/colMeans(chain5$THETA))
CVMC_SIG_5 <- 100*abs(EMC_SIG_5/colMeans(chain5$SIG2))
CVMC_OTROS_5 <- 100*abs(EMC_OTROS_5/colMeans(chain5$OTROS))

(summary(round(CVMC_ZETA_5,digits = 4)))
(summary(round(CVMC_THETA_5,digits = 4)))
(summary(round(CVMC_SIG_5,digits = 4)))
(round(CVMC_OTROS_5,digits = 4))
```

## Punto 4
```{r Punto 4}
par(mfrow = c(2, 2))

# Gráfico 1 (negro)
plot(x = 1:10000, y = unlist(chain2$LL), type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud", col = "black", ylim = c(-2797969-5000, -2775317+5000))
title("M2")

# Gráfico 2 (rojo)
plot(x = 1:10000, y = unlist(chain3$LL), type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud", col = "red",ylim = c(-2797969-5000, -2775317+5000))
title("M3")

# Gráfico 3 (azul)
plot(x = 1:10000, y = unlist(chain4$LL), type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud", col = "blue",ylim =c(-2797969-5000, -2775317+5000))
title("M4")

# Gráfico 4 (verde)
plot(x = 1:10000, y = unlist(chain5$LL), type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud", col = "green",ylim = c(-2797969-5000, -2775317+5000))
title("M5")

```

## Punto 5
```{r Punto 5}
nj <- datos %>%
  group_by(COLE_COD_DEPTO_UBICACION) %>%
  summarise(nj = n()) %>%
  pull(nj)
m <- length(nj)

##DIC

#M1
LP1 <- as.numeric(chain1$LL$ll)
thetahat_1 <- mean(chain1$THETA[,1])
sigma2hat_1 <- mean(chain1$THETA[,2])
lpyth_m1 <- sum(dnorm(x = y,mean = thetahat_1,sd = sqrt(sigma2hat_1),log = T))
pDIC_m1 <- 2*(lpyth_m1-mean(LP1))
dic_m1 <- -2*lpyth_m1 + 2*pDIC_m1

#M2 
LP2 <- as.numeric(chain2$LL$ll)
thetahat_2 <- colMeans(chain2$THETA[,1:m])
sigma2hat_2 <- mean(chain2$THETA$sig2)
lpyth_m2 <- sum(dnorm(x = y,mean =rep(thetahat_2,nj),sd = sqrt(sigma2hat_2),log = T))
pDIC_m2 <- 2*(lpyth_m2-mean(LP2))
dic_m2 <- -2*lpyth_m2 + 2*pDIC_m2

#M3
LP3 <- as.numeric(chain3$LL$ll)
thetahat_3 <- colMeans(chain3$THETA[,1:m])
sigma2hat_3 <- colMeans(chain3$THETA[,(m+1):(m*2)])
lpyth_m3 <- sum(dnorm(x = y,mean =rep(thetahat_3,nj),sd = sqrt(rep(sigma2hat_3,nj)),log = T))
pDIC_m3 <- 2*(lpyth_m3-mean(LP3))
dic_m3 <- -2*lpyth_m3 + 2*pDIC_m3


#M4
LP4 <- as.numeric(chain4$LL$ll)
zetahat_4 <- colMeans(chain4$ZETA)
kappa2hat_4 <- mean(chain4$OTROS$k2)
lpyth_m4 <- sum(dnorm(x = y, mean = zetahat_4, sd = sqrt(kappa2hat_4),log = T))
pDIC_m4 <- 2*(lpyth_m4-mean(LP4))
dic_m4 <- -2*lpyth_m4 + 2*pDIC_m4

#M5
LP5 <- as.numeric(chain5$LL$ll)
zetahat_5 <- colMeans(chain5$ZETA)
kappa2hat_5 <- mean(chain5$OTROS$k2)
lpyth_m5 <- sum(dnorm(x = y, mean = zetahat_5, sd = sqrt(kappa2hat_5),log = T))
pDIC_m5 <- 2*(lpyth_m5-mean(LP5))
dic_m5 <- -2*lpyth_m5+2*pDIC_m5


DICs <- c(dic_m1,dic_m2,dic_m3,dic_m4,dic_m5)
DICs

(which.min(DICs))


```

```{r Punto 5 WAIC}
n <- length(datos$PUNT_GLOBAL)
y <- datos$PUNT_GLOBAL
Y <- vector(mode = "list", length = m)
g <- rep(NA, n)
for (j in 1:m) {
  idx <- datos$ESTU_CONSECUTIVO == unique(datos$ESTU_CONSECUTIVO)[j]
  g[idx] <- j
  Y[[j]] <- y[idx]
}
```

## Punto 6
```{r  Punto 6}

vecmu <- cbind(chain1$THETA[,1],chain2$THETA$mu,chain3$THETA$mu,chain4$OTROS$mu,chain5$OTROS$mu)

medias <- apply(vecmu, MARGIN = 2, mean)
medias <- round(medias, digits = 2)

ICs <- apply(vecmu, MARGIN = 2, function(x) quantile(x, c(0.025, 0.975)))
ICs <- round(ICs, digits = 3)

punto_6 <- rbind(medias,ICs)

`colnames<-`(punto_6,c("M1","M2","M3","M4","M5"))
print(punto_6)
```

## Punto 7
```{r Punto 7}
estadisticos <- datos %>% 
  group_by(datos$COLE_COD_DEPTO_UBICACION) %>% 
  summarise(codigo = unique(COLE_COD_DEPTO_UBICACION), 
            nombre = unique(COLE_DEPTO_UBICACION), 
            nj = n(), 
            yb = mean(PUNT_GLOBAL), 
            s2 = var(PUNT_GLOBAL))

ids2 <- estadisticos$nombre
yb <- estadisticos$yb
that <- yb
s2 <- estadisticos$s2
ic1  <- NULL


# ranking Bayesiano
ids2 <- estadisticos$nombre
that <- colMeans(chain5$THETA[,1:m])
ic1  <- apply(X = chain5$THETA[,1:m], MARGIN = 2, FUN = function(x) quantile(x, c(0.025,0.975)))
ranking <- order(that) 
ids2 <- ids2[ ranking]
that <- that[ ranking]
ic1  <- ic1 [,ranking]
colo <- rep(2,m)
colo[which(ic1[1,]>250)] <- 1
colo[which(ic1[2,]<250)] <- 3
colo <- c("green4","black","red")[colo]
# gráfico
par(mfrow = c(1,2), mar = c(4,10,1.5,1), mgp = c(2.5,0.75,0))
plot(NA, NA, xlab = "Puntaje", ylab = "", main = "Ranking Bayesiano", xlim = c(180,320), ylim = c(1,m), cex.axis = 0.75, yaxt = "n")
axis(side = 2, at = 1:m, labels = ids2, las = 2)
abline(v = 250,  col = "gray", lwd = 3)
abline(h = 1:m, col = "lightgray", lwd = 1)
for (j in 1:m) {
  segments(x0 = ic1[1,j], y0 = j, x1 = ic1[2,j], y1 = j, col = colo[j])
  lines(x = that[j], y = j, type = "p", pch = 16, cex = 0.8, col = colo[j])
}

estadisticos <- datos %>% 
  group_by(datos$COLE_COD_DEPTO_UBICACION) %>% 
  summarise(codigo = unique(COLE_COD_DEPTO_UBICACION), 
            nombre = unique(COLE_DEPTO_UBICACION), 
            nj = n(), 
            yb = mean(PUNT_GLOBAL), 
            s2 = var(PUNT_GLOBAL))

ids2 <- estadisticos$nombre
yb <- estadisticos$yb
that <- yb
s2 <- estadisticos$s2
ic1  <- NULL


#Frecuentista
for (j in 1:m)
  ic1  <- cbind(ic1, yb[j] + c(-1,1)*qnorm(p = 0.975)*sqrt(s2[j])/sqrt(nj[j]))
ranking <- order(that) 
ids2 <- ids2[ranking]
that <- that[ranking]
ic1  <- ic1 [,ranking]
colo <- rep(2,m)
colo[which(ic1[1,]>250)] <- 1
colo[which(ic1[2,]<250)] <- 3
colo <- c("green4","black","red")[colo]
# gráfico
plot(NA, NA, xlab = "Puntaje", ylab = "", main = "Ranking Frecuentista", xlim = c(180,320), ylim = c(1,m), cex.axis = 0.75, yaxt = "n")
axis(side = 2, at = 1:m, labels = ids2, las = 2)
abline(v = 250,  col = "gray", lwd = 3)
abline(h = 1:m, col = "lightgray", lwd = 1)
for (j in 1:m) {
  segments(x0 = ic1[1,j], y0 = j, x1 = ic1[2,j], y1 = j, col = colo[j],lwd = 2)
  lines(x = that[j], y = j, type = "p", pch = 16, cex = 0.8, col = colo[j])
}
```
## Punto 8
```{r Punto 8}
# k means para cada iteracion

# Número de clústeres deseados
clusters <-5

# Inicializa una lista para almacenar los resultados
kmedias <- matrix(NA,nrow=10000,ncol=32)

# Realiza K-Means en cada fila de la matriz de datos
for (i in 1:10000) {
  departamentos <- t(chain5$THETA) # Obtiene la fila i
  clusters_kmedias <- kmeans(departamentos, centers = clusters)  # Aplica K-Means a la fila
  kmedias[i,] <- clusters_kmedias$cluster  # Almacena el 
}

B <- nrow(chain5$THETA)
B_grid <- seq(from = 5, to = B, len = B/10)
# matriz de incidencia
A <- matrix(data = 0, nrow = m, ncol = m)
for (b in B_) {
  for (i in 1:(m-1)) {
    for (j in (i+1):m) {
      if (kmedias$XI[b,i] == kmedias$XI[b,j]) {
        A[i,j] <- A[i,j] + 1/B
      } 
    }
  }
}
A <- A + t(A)
diag(A) <- 1
# se organizan las observaciones de acuerdo a la partición verdadera
indices <- order(xi)
A <- A[indices,indices]
# visualización de la matriz de incidencia
par(mar = c(2.75,2.75,0.5,0.5), mgp = c(1.7,0.7,0))
corrplot::corrplot(corr = A, is.corr = FALSE, addgrid.col = NA, method = "color", tl.pos = "n")
```

## Punto 9
```{r}
regresion <- Mapa %>%
  select(cod_dep, dep, IP2018) %>%
  as.data.frame()

predicciones <- matrix(data = NA, nrow = 10000, ncol=8)

for (b in 1:10000) {
  media <- unlist(chain5$THETA[b,]) 
  regresion$media <- media
  modelo <- lm(IP2018 ~ media, data = regresion)
  last_8_rows <- media[(length(media) - 7):length(media)]
  new_data <- data.frame(media = last_8_rows)
  a = predict(modelo,newdata = new_data)
  predicciones[b, ] <- a
}

predIP2018 <- colMeans(predicciones)



```
  


```{r}
#load("C:/Users/jher/Documents/GitHub/BayesianStatsCase2/chain1.Rdata")
#load("C:/Users/jher/Documents/GitHub/BayesianStatsCase2/chain2.Rdata")
#load("C:/Users/jher/Documents/GitHub/BayesianStatsCase2/chain3.Rdata")
#load("C:/Users/jher/Documents/GitHub/BayesianStatsCase2/chain4.Rdata")
#load("C:/Users/jher/Documents/GitHub/BayesianStatsCase2/chain5.Rdata")
```

```{r}
save(chain1,file = "chain1.Rdata")
save(chain2,file = "chain2.Rdata")
save(chain3,file = "chain3.Rdata")
save(chain4,file = "chain4.Rdata")
save(chain5,file = "chain5.Rdata")
```

